{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica para Sistemas de Bases de Datos (Feb 21)\n",
    "\n",
    "## Autor: Martín Romera Sobrado\n",
    "## Contacto: mromera95@alumno.uned.es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización de la base de datos\n",
    "\n",
    "Creamos e iniciamos la base de datos si todavía no lo está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir librosdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir librosdb/authors/ && hadoop fs -mkdir librosdb/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 18ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "que no este creada.alhost:10000/default> -- Crea la base de datos en el caso de  \n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "0: jdbc:hive2://localhost:10000/default> create database if not exists librosdb\n",
      "de libros'. . . . . . . . . . . . . . .> Comment 'Base de datos con información  \n",
      ". . . . . . . . . . . . . . . . . . . .> Location '/home/cloudera/librosdb'\n",
      "n Romera Sobrado', 'Creada. . . . . . .> With dbproperties('Creada por' = 'Martí  el' = '9-Nov-2020');\n",
      "INFO  : Compiling command(queryId=hive_20201229052727_e9c15f94-d17c-4a66-96c1-69b673397e7c): create database if not exists librosdb\n",
      "Comment 'Base de datos con información de libros'\n",
      "Location '/home/cloudera/librosdb'\n",
      "With dbproperties('Creada por' = 'Martín Romera Sobrado', 'Creada el' = '9-Nov-2020')\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_e9c15f94-d17c-4a66-96c1-69b673397e7c); Time taken: 0.494 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_e9c15f94-d17c-4a66-96c1-69b673397e7c): create database if not exists librosdb\n",
      "Comment 'Base de datos con información de libros'\n",
      "Location '/home/cloudera/librosdb'\n",
      "With dbproperties('Creada por' = 'Martín Romera Sobrado', 'Creada el' = '9-Nov-2020')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_e9c15f94-d17c-4a66-96c1-69b673397e7c); Time taken: 1.276 seconds\n",
      "INFO  : OK\n",
      "No rows affected (1.984 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -f db/db.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de *db/db.hql* son los siguientes:\n",
    "\n",
    "```HiveQL\n",
    "create database if not exists librosdb\n",
    "Comment 'Base de datos con información de libros'\n",
    "Location '/home/cloudera/librosdb'\n",
    "With dbproperties('Creada por' = 'Martín Romera Sobrado', 'Creada el' = '9-Nov-2020');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ej 1. *Crea las tablas necesarias para almacenar los datos. Pueden ser internas o externas en función de los datos que se desee. La decisión de interna o externa debe estar razonada.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tablas serán externas, ya que en el ejercicio 5 tendremos un programa *MapReduce* en python que acceda a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "0: jdbc:hive2://localhost:10000/> -- Creamos las dos tablas: authors y datasets\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> USE librosdb;\n",
      "INFO  : Compiling command(queryId=hive_20201229052727_cad66978-5868-4a8c-8c89-ad6118c305df): USE librosdb\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_cad66978-5868-4a8c-8c89-ad6118c305df); Time taken: 0.074 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_cad66978-5868-4a8c-8c89-ad6118c305df): USE librosdb\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_cad66978-5868-4a8c-8c89-ad6118c305df); Time taken: 0.011 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.138 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> -- Tabla authors\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> CREATE EXTERNAL TABLE IF NOT EXISTS authors\n",
      ". . . . . . . . . . . . . . . . > (\n",
      ". . . . . . . . . . . . . . . . >     author_id INT,\n",
      ". . . . . . . . . . . . . . . . >     author_name STRING\n",
      ". . . . . . . . . . . . . . . . > )\n",
      ". . . . . . . . . . . . . . . . > COMMENT 'Tabla de autores'\n",
      ". . . . . . . . . . . . . . . . > ROW FORMAT DELIMITED\n",
      ". . . . . . . . . . . . . . . . > FIELDS TERMINATED BY '\\;'\n",
      ". . . . . . . . . . . . . . . . > tblproperties(\"skip.header.line.count\"=\"1\"); \n",
      "INFO  : Compiling command(queryId=hive_20201229052727_44341d7a-1f41-4adb-b395-ff86a2c50daf): CREATE EXTERNAL TABLE IF NOT EXISTS authors\n",
      "(\n",
      "author_id INT,\n",
      "author_name STRING\n",
      ")\n",
      "COMMENT 'Tabla de autores'\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ';'\n",
      "tblproperties(\"skip.header.line.count\"=\"1\")\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_44341d7a-1f41-4adb-b395-ff86a2c50daf); Time taken: 0.203 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_44341d7a-1f41-4adb-b395-ff86a2c50daf): CREATE EXTERNAL TABLE IF NOT EXISTS authors\n",
      "(\n",
      "author_id INT,\n",
      "author_name STRING\n",
      ")\n",
      "COMMENT 'Tabla de autores'\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ';'\n",
      "tblproperties(\"skip.header.line.count\"=\"1\")\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_44341d7a-1f41-4adb-b395-ff86a2c50daf); Time taken: 0.275 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.498 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> -- Tabla dataset\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> CREATE EXTERNAL TABLE IF NOT EXISTS dataset\n",
      ". . . . . . . . . . . . . . . . > (\n",
      ". . . . . . . . . . . . . . . . >     title STRING,\n",
      ". . . . . . . . . . . . . . . . >     author_id INT,\n",
      ". . . . . . . . . . . . . . . . >     bestsellers_rank INT,\n",
      ". . . . . . . . . . . . . . . . >     imprint BINARY,\n",
      ". . . . . . . . . . . . . . . . >     publication_date STRING,\n",
      ". . . . . . . . . . . . . . . . >     rating_avg DOUBLE,\n",
      ". . . . . . . . . . . . . . . . >     rating_count INT\n",
      ". . . . . . . . . . . . . . . . > )\n",
      ". . . . . . . . . . . . . . . . > COMMENT 'Tabla de libros'\n",
      ". . . . . . . . . . . . . . . . > ROW FORMAT DELIMITED\n",
      ". . . . . . . . . . . . . . . . > FIELDS TERMINATED BY '\\;'\n",
      ". . . . . . . . . . . . . . . . > tblproperties(\"skip.header.line.count\"=\"1\"); \n",
      "INFO  : Compiling command(queryId=hive_20201229052727_6cfb9968-9e49-48e5-87b8-479761b672f1): CREATE EXTERNAL TABLE IF NOT EXISTS dataset\n",
      "(\n",
      "title STRING,\n",
      "author_id INT,\n",
      "bestsellers_rank INT,\n",
      "imprint BINARY,\n",
      "publication_date STRING,\n",
      "rating_avg DOUBLE,\n",
      "rating_count INT\n",
      ")\n",
      "COMMENT 'Tabla de libros'\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ';'\n",
      "tblproperties(\"skip.header.line.count\"=\"1\")\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_6cfb9968-9e49-48e5-87b8-479761b672f1); Time taken: 0.011 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_6cfb9968-9e49-48e5-87b8-479761b672f1): CREATE EXTERNAL TABLE IF NOT EXISTS dataset\n",
      "(\n",
      "title STRING,\n",
      "author_id INT,\n",
      "bestsellers_rank INT,\n",
      "imprint BINARY,\n",
      "publication_date STRING,\n",
      "rating_avg DOUBLE,\n",
      "rating_count INT\n",
      ")\n",
      "COMMENT 'Tabla de libros'\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ';'\n",
      "tblproperties(\"skip.header.line.count\"=\"1\")\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_6cfb9968-9e49-48e5-87b8-479761b672f1); Time taken: 0.064 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.092 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -f db/ej1.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de ej1.hql son los siguientes:\n",
    "```HiveQL\n",
    "-- Creamos las dos tablas: authors y datasets\n",
    "\n",
    "USE librosdb;\n",
    "\n",
    "-- Tabla authors\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS authors\n",
    "(\n",
    "    author_id INT,\n",
    "    author_name STRING\n",
    ")\n",
    "COMMENT 'Tabla de autores'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY '\\;'\n",
    "tblproperties(\"skip.header.line.count\"=\"1\"); \n",
    "\n",
    "-- Tabla dataset\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS dataset\n",
    "(\n",
    "    title STRING,\n",
    "    author_id INT,\n",
    "    bestsellers_rank INT,\n",
    "    imprint BINARY,\n",
    "    publication_date STRING,\n",
    "    rating_avg DOUBLE,\n",
    "    rating_count INT\n",
    ")\n",
    "COMMENT 'Tabla de libros'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY '\\;'\n",
    "tblproperties(\"skip.header.line.count\"=\"1\"); \n",
    "```\n",
    "\n",
    "Ej 2. *Importa los datos en las tablas creadas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put db/csv/authors.csv librosdb/authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put db/csv/dataset.csv librosdb/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 4ms\n",
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "tosjdbc:hive2://localhost:10000/> -- Importamos datos de los csv a la base de da \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> USE librosdb;\n",
      "INFO  : Compiling command(queryId=hive_20201229052727_0344d4d5-8f27-4b26-adeb-a62c4fdd75f6): USE librosdb\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_0344d4d5-8f27-4b26-adeb-a62c4fdd75f6); Time taken: 0.087 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_0344d4d5-8f27-4b26-adeb-a62c4fdd75f6): USE librosdb\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_0344d4d5-8f27-4b26-adeb-a62c4fdd75f6); Time taken: 0.012 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.16 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "ors/authors.csv' INTO TABLE authors;AD DATA INPATH '/user/cloudera/librosdb/auth \n",
      "INFO  : Compiling command(queryId=hive_20201229052727_60b6ad72-6f0f-4013-bd99-7f304e9f467d): LOAD DATA INPATH '/user/cloudera/librosdb/authors/authors.csv' INTO TABLE authors\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_60b6ad72-6f0f-4013-bd99-7f304e9f467d); Time taken: 0.082 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_60b6ad72-6f0f-4013-bd99-7f304e9f467d): LOAD DATA INPATH '/user/cloudera/librosdb/authors/authors.csv' INTO TABLE authors\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table librosdb.authors from hdfs://quickstart.cloudera:8020/user/cloudera/librosdb/authors/authors.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Table librosdb.authors stats: [numFiles=1, totalSize=464036]\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_60b6ad72-6f0f-4013-bd99-7f304e9f467d); Time taken: 0.705 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.802 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "set/dataset.csv' INTO TABLE dataset;AD DATA INPATH '/user/cloudera/librosdb/data \n",
      "INFO  : Compiling command(queryId=hive_20201229052727_45cc6072-4836-409e-874a-1e64e5a17316): LOAD DATA INPATH '/user/cloudera/librosdb/dataset/dataset.csv' INTO TABLE dataset\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_45cc6072-4836-409e-874a-1e64e5a17316); Time taken: 0.073 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_45cc6072-4836-409e-874a-1e64e5a17316): LOAD DATA INPATH '/user/cloudera/librosdb/dataset/dataset.csv' INTO TABLE dataset\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table librosdb.dataset from hdfs://quickstart.cloudera:8020/user/cloudera/librosdb/dataset/dataset.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Table librosdb.dataset stats: [numFiles=1, totalSize=3391054]\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_45cc6072-4836-409e-874a-1e64e5a17316); Time taken: 0.272 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.36 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -f db/ej2.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de el archivo *db/ej2.hql*, son los siguientes:\n",
    "\n",
    "```HiveQL\n",
    "-- Importamos datos de los csv a la base de datos\n",
    "\n",
    "USE librosdb;\n",
    "\n",
    "LOAD DATA INPATH '/user/cloudera/librosdb/authors/authors.csv' INTO TABLE authors;\n",
    "\n",
    "LOAD DATA INPATH '/user/cloudera/librosdb/dataset/dataset.csv' INTO TABLE dataset;\n",
    "```\n",
    "\n",
    "Los dos ficheros csv, son los que proporcionan para la práctica, sin se alterados en ningún momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ej 3. *Crea una vista sobre las tablas creadas. Esta vista tendrá para cada título, el nombre del autor, fecha de publicación, y valoración media.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "los siguientes atributos::10000/> -- Crea una vista para las tablas creadas con  \n",
      "ión y Valoración mediaost:10000/> -- Titulo, Nombre del autor, Fecha de publicac \n",
      "0: jdbc:hive2://localhost:10000/> USE librosdb;\n",
      "INFO  : Compiling command(queryId=hive_20201229052727_ef8b2bef-4ec1-47d7-8e90-1c422b783f22): USE librosdb\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_ef8b2bef-4ec1-47d7-8e90-1c422b783f22); Time taken: 0.073 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_ef8b2bef-4ec1-47d7-8e90-1c422b783f22): USE librosdb\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_ef8b2bef-4ec1-47d7-8e90-1c422b783f22); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.133 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> CREATE VIEW IF NOT EXISTS vista_libros \n",
      ". . . . . . . . . . . . . . . . > (\n",
      ". . . . . . . . . . . . . . . . >     title COMMENT 'Titulo del libro',\n",
      ". . . . . . . . . . . . . . . . >     author_name COMMENT 'Autor del libro',\n",
      "ción',. . . . . . . . . . . . . >     publication_date COMMENT 'Fecha de publica \n",
      "ibro' . . . . . . . . . . . . . >     rating_avg COMMENT 'Valoración media del l \n",
      ". . . . . . . . . . . . . . . . > )\n",
      ", rating_avg. . . . . . . . . . > AS SELECT title, author_name, publication_date \n",
      ". . . . . . . . . . . . . . . . > FROM authors, dataset\n",
      ". . . . . . . . . . . . . . . . > WHERE authors.author_id = dataset.author_id;\n",
      "INFO  : Compiling command(queryId=hive_20201229052727_b3add9e0-7b8d-4c15-8218-96bd409f2035): CREATE VIEW IF NOT EXISTS vista_libros\n",
      "(\n",
      "title COMMENT 'Titulo del libro',\n",
      "author_name COMMENT 'Autor del libro',\n",
      "publication_date COMMENT 'Fecha de publicación',\n",
      "rating_avg COMMENT 'Valoración media del libro'\n",
      ")\n",
      "AS SELECT title, author_name, publication_date, rating_avg\n",
      "FROM authors, dataset\n",
      "WHERE authors.author_id = dataset.author_id\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:title, type:string, comment:null), FieldSchema(name:author_name, type:string, comment:null), FieldSchema(name:publication_date, type:string, comment:null), FieldSchema(name:rating_avg, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052727_b3add9e0-7b8d-4c15-8218-96bd409f2035); Time taken: 0.604 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052727_b3add9e0-7b8d-4c15-8218-96bd409f2035): CREATE VIEW IF NOT EXISTS vista_libros\n",
      "(\n",
      "title COMMENT 'Titulo del libro',\n",
      "author_name COMMENT 'Autor del libro',\n",
      "publication_date COMMENT 'Fecha de publicación',\n",
      "rating_avg COMMENT 'Valoración media del libro'\n",
      ")\n",
      "AS SELECT title, author_name, publication_date, rating_avg\n",
      "FROM authors, dataset\n",
      "WHERE authors.author_id = dataset.author_id\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052727_b3add9e0-7b8d-4c15-8218-96bd409f2035); Time taken: 0.03 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.66 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -f db/ej3.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de ej3.hql son:\n",
    "```HiveQL\n",
    "-- Crea una vista para las tablas creadas con los siguientes atributos:\n",
    "-- Titulo, Nombre del autor, Fecha de publicación y Valoración media\n",
    "USE librosdb;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS vista_libros \n",
    "(\n",
    "    title COMMENT 'Titulo del libro',\n",
    "    author_name COMMENT 'Autor del libro',\n",
    "    publication_date COMMENT 'Fecha de publicación',\n",
    "    rating_avg COMMENT 'Valoración media del libro'\n",
    ")\n",
    "AS SELECT title, author_name, publication_date, rating_avg\n",
    "FROM authors, dataset\n",
    "WHERE authors.author_id = dataset.author_id;\n",
    "```\n",
    "\n",
    "Ej 4. *Crea las consultas de hive para responder las siguientes cuestiones:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *¿Cuál es el título del libro que ocupa el primer lugar en el ranking de bestsellers?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "de bestsellers//localhost:10000/> -- Selecciona el libro más alto en el ranking  \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> USE librosdb;\n",
      "INFO  : Compiling command(queryId=hive_20201229052828_8d38ecea-e7c0-4668-8222-3e34d7c41bd5): USE librosdb\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052828_8d38ecea-e7c0-4668-8222-3e34d7c41bd5); Time taken: 0.052 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052828_8d38ecea-e7c0-4668-8222-3e34d7c41bd5): USE librosdb\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052828_8d38ecea-e7c0-4668-8222-3e34d7c41bd5); Time taken: 0.009 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.105 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> SELECT title\n",
      ". . . . . . . . . . . . . . . . > FROM dataset LEFT SEMI JOIN (\n",
      ". . . . . . . . . . . . . . . . >     SELECT min(bestsellers_rank) AS bestseller \n",
      ". . . . . . . . . . . . . . . . >     FROM dataset\n",
      ". . . . . . . . . . . . . . . . > ) AS a \n",
      ". . . . . . . . . . . . . . . . > ON bestsellers_rank = a.bestseller\n",
      ". . . . . . . . . . . . . . . . > LIMIT 1;\n",
      "INFO  : Compiling command(queryId=hive_20201229052828_8290aa91-16b0-4e9c-9a8f-1f296a0bc80d): SELECT title\n",
      "FROM dataset LEFT SEMI JOIN (\n",
      "SELECT min(bestsellers_rank) AS bestseller\n",
      "FROM dataset\n",
      ") AS a\n",
      "ON bestsellers_rank = a.bestseller\n",
      "LIMIT 1\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:title, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052828_8290aa91-16b0-4e9c-9a8f-1f296a0bc80d); Time taken: 0.676 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052828_8290aa91-16b0-4e9c-9a8f-1f296a0bc80d): SELECT title\n",
      "FROM dataset LEFT SEMI JOIN (\n",
      "SELECT min(bestsellers_rank) AS bestseller\n",
      "FROM dataset\n",
      ") AS a\n",
      "ON bestsellers_rank = a.bestseller\n",
      "LIMIT 1\n",
      "INFO  : Query ID = hive_20201229052828_8290aa91-16b0-4e9c-9a8f-1f296a0bc80d\n",
      "INFO  : Total jobs = 3\n",
      "INFO  : Launching Job 1 out of 3\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1604927967949_0001, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0001/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0001\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2020-12-29 05:28:14,750 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:28:20,023 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec\n",
      "INFO  : 2020-12-29 05:28:26,731 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.29 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 290 msec\n",
      "INFO  : Ended Job = job_1604927967949_0001\n",
      "INFO  : Starting task [Stage-5:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-6 is selected by condition resolver.\n",
      "INFO  : Stage-2 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-6:MAPREDLOCAL] in serial mode\n",
      "Execution log at: /var/log/hive/hive-server2.log\n",
      "2020-12-29 05:28:31\tStarting to launch local task to process map join;\tmaximum memory = 932184064\n",
      "2020-12-29 05:28:32\tDump the side-table for tag: 1 with group count: 1 into file: file:/tmp/hive/9e24ad9b-cebb-4c58-899f-cafd9a9a6f4b/hive_2020-12-29_05-28-04_097_6330752846831795998-2/-local-10004/HashTable-Stage-4/MapJoin-mapfile01--.hashtable\n",
      "2020-12-29 05:28:32\tUploaded 1 File to: file:/tmp/hive/9e24ad9b-cebb-4c58-899f-cafd9a9a6f4b/hive_2020-12-29_05-28-04_097_6330752846831795998-2/-local-10004/HashTable-Stage-4/MapJoin-mapfile01--.hashtable (278 bytes)\n",
      "2020-12-29 05:28:32\tEnd of local task; Time Taken: 0.71 sec.\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 3 out of 3\n",
      "INFO  : Starting task [Stage-4:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : Starting Job = job_1604927967949_0002, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0002/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0002\n",
      "INFO  : Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2020-12-29 05:28:38,668 Stage-4 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:28:43,888 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.1 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 100 msec\n",
      "INFO  : Ended Job = job_1604927967949_0002\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.29 sec   HDFS Read: 3398110 HDFS Write: 114 SUCCESS\n",
      "INFO  : Stage-Stage-4: Map: 1   Cumulative CPU: 2.1 sec   HDFS Read: 3397078 HDFS Write: 79 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 5 seconds 390 msec\n",
      "INFO  : Completed executing command(queryId=hive_20201229052828_8290aa91-16b0-4e9c-9a8f-1f296a0bc80d); Time taken: 40.099 seconds\n",
      "INFO  : OK\n",
      "+----------------------------------------------------+--+\n",
      "|                       title                        |\n",
      "+----------------------------------------------------+--+\n",
      "| Atlas Obscura, 2nd Edition : An Explorer's Guide to the World's Hidden Wonders |\n",
      "+----------------------------------------------------+--+\n",
      "1 row selected (41.086 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -f db/ej4_a.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de ej4_a.hql son:\n",
    "```HiveQL\n",
    "-- Selecciona el libro más alto en el ranking de bestsellers\n",
    "\n",
    "USE librosdb;\n",
    "\n",
    "SELECT title\n",
    "FROM dataset LEFT SEMI JOIN (\n",
    "    SELECT min(bestsellers_rank) AS bestseller\n",
    "    FROM dataset\n",
    ") AS a \n",
    "ON bestsellers_rank = a.bestseller\n",
    "LIMIT 1;\n",
    "```\n",
    "\n",
    "- *¿Cuál es el título del libro con mejor valoración media de la autora Ana Maria Spagna?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      " Ana Maria Spagnaocalhost:10000/> -- Selecciona el libro con mejor valoración de \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> USE librosdb;\n",
      "INFO  : Compiling command(queryId=hive_20201229052828_b291abd8-6071-4e60-81d5-e1e58d2c063e): USE librosdb\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052828_b291abd8-6071-4e60-81d5-e1e58d2c063e); Time taken: 0.051 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052828_b291abd8-6071-4e60-81d5-e1e58d2c063e): USE librosdb\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052828_b291abd8-6071-4e60-81d5-e1e58d2c063e); Time taken: 0.011 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.108 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> SELECT title\n",
      ". . . . . . . . . . . . . . . . > FROM(\n",
      ". . . . . . . . . . . . . . . . >     SELECT title, rating_avg\n",
      ". . . . . . . . . . . . . . . . >     FROM dataset LEFT SEMI JOIN (\n",
      ". . . . . . . . . . . . . . . . >         SELECT max(rating_avg) AS max_rating\n",
      ". . . . . . . . . . . . . . . . >         FROM authors, dataset\n",
      "or_id AND authors.author_name = \"Ana Maria Spagna\"thors.author_id = dataset.auth \n",
      ". . . . . . . . . . . . . . . . >     ) AS b\n",
      ". . . . . . . . . . . . . . . . >     ON rating_avg = b.max_rating\n",
      ". . . . . . . . . . . . . . . . > ) AS a\n",
      ". . . . . . . . . . . . . . . . > LIMIT 1;\n",
      "INFO  : Compiling command(queryId=hive_20201229052828_b55df780-04ee-409e-82f5-7c4836de11fa): SELECT title\n",
      "FROM(\n",
      "SELECT title, rating_avg\n",
      "FROM dataset LEFT SEMI JOIN (\n",
      "SELECT max(rating_avg) AS max_rating\n",
      "FROM authors, dataset\n",
      "WHERE authors.author_id = dataset.author_id AND authors.author_name = \"Ana Maria Spagna\"\n",
      ") AS b\n",
      "ON rating_avg = b.max_rating\n",
      ") AS a\n",
      "LIMIT 1\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:title, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052828_b55df780-04ee-409e-82f5-7c4836de11fa); Time taken: 2.008 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052828_b55df780-04ee-409e-82f5-7c4836de11fa): SELECT title\n",
      "FROM(\n",
      "SELECT title, rating_avg\n",
      "FROM dataset LEFT SEMI JOIN (\n",
      "SELECT max(rating_avg) AS max_rating\n",
      "FROM authors, dataset\n",
      "WHERE authors.author_id = dataset.author_id AND authors.author_name = \"Ana Maria Spagna\"\n",
      ") AS b\n",
      "ON rating_avg = b.max_rating\n",
      ") AS a\n",
      "LIMIT 1\n",
      "INFO  : Query ID = hive_20201229052828_b55df780-04ee-409e-82f5-7c4836de11fa\n",
      "INFO  : Total jobs = 3\n",
      "INFO  : Starting task [Stage-10:MAPREDLOCAL] in serial mode\n",
      "Execution log at: /var/log/hive/hive-server2.log\n",
      "2020-12-29 05:28:55\tStarting to launch local task to process map join;\tmaximum memory = 932184064\n",
      "2020-12-29 05:28:56\tDump the side-table for tag: 0 with group count: 1 into file: file:/tmp/hive/47716657-2c36-45f7-821e-365589b8b9fd/hive_2020-12-29_05-28-50_773_6670114008671866415-2/-local-10008/HashTable-Stage-2/MapJoin-mapfile20--.hashtable\n",
      "2020-12-29 05:28:56\tUploaded 1 File to: file:/tmp/hive/47716657-2c36-45f7-821e-365589b8b9fd/hive_2020-12-29_05-28-50_773_6670114008671866415-2/-local-10008/HashTable-Stage-2/MapJoin-mapfile20--.hashtable (278 bytes)\n",
      "2020-12-29 05:28:56\tEnd of local task; Time Taken: 1.298 sec.\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 3\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1604927967949_0003, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0003/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0003\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2020-12-29 05:29:02,749 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:29:10,089 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.18 sec\n",
      "INFO  : 2020-12-29 05:29:17,492 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.18 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 180 msec\n",
      "INFO  : Ended Job = job_1604927967949_0003\n",
      "INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-9 is selected by condition resolver.\n",
      "INFO  : Stage-3 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-9:MAPREDLOCAL] in serial mode\n",
      "Execution log at: /var/log/hive/hive-server2.log\n",
      "2020-12-29 05:29:22\tStarting to launch local task to process map join;\tmaximum memory = 932184064\n",
      "2020-12-29 05:29:23\tDump the side-table for tag: 1 with group count: 1 into file: file:/tmp/hive/47716657-2c36-45f7-821e-365589b8b9fd/hive_2020-12-29_05-28-50_773_6670114008671866415-2/-local-10006/HashTable-Stage-6/MapJoin-mapfile11--.hashtable\n",
      "2020-12-29 05:29:23\tUploaded 1 File to: file:/tmp/hive/47716657-2c36-45f7-821e-365589b8b9fd/hive_2020-12-29_05-28-50_773_6670114008671866415-2/-local-10006/HashTable-Stage-6/MapJoin-mapfile11--.hashtable (285 bytes)\n",
      "2020-12-29 05:29:23\tEnd of local task; Time Taken: 0.704 sec.\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 3 out of 3\n",
      "INFO  : Starting task [Stage-6:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : Starting Job = job_1604927967949_0004, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0004/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0004\n",
      "INFO  : Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2020-12-29 05:29:28,376 Stage-6 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:29:34,665 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.5 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 500 msec\n",
      "INFO  : Ended Job = job_1604927967949_0004\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.18 sec   HDFS Read: 3402776 HDFS Write: 121 SUCCESS\n",
      "INFO  : Stage-Stage-6: Map: 1   Cumulative CPU: 2.5 sec   HDFS Read: 3397195 HDFS Write: 64 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 6 seconds 680 msec\n",
      "INFO  : Completed executing command(queryId=hive_20201229052828_b55df780-04ee-409e-82f5-7c4836de11fa); Time taken: 42.969 seconds\n",
      "INFO  : OK\n",
      "+----------------------------------------------------+--+\n",
      "|                       title                        |\n",
      "+----------------------------------------------------+--+\n",
      "| 100 Skills You'll Need for the End of the World (as We Know It) |\n",
      "+----------------------------------------------------+--+\n",
      "1 row selected (45.054 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -f db/ej4_b.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de ej4_b.hql son:\n",
    "```HiveQL\n",
    "-- Selecciona el libro con mejor valoración de Ana Maria Spagna\n",
    "\n",
    "USE librosdb;\n",
    "\n",
    "SELECT title\n",
    "FROM(\n",
    "    SELECT title, rating_avg\n",
    "    FROM dataset LEFT SEMI JOIN (\n",
    "        SELECT max(rating_avg) AS max_rating\n",
    "        FROM authors, dataset\n",
    "        WHERE authors.author_id = dataset.author_id AND authors.author_name = \"Ana Maria Spagna\"\n",
    "    ) AS b\n",
    "    ON rating_avg = b.max_rating\n",
    ") AS a\n",
    "LIMIT 1;\n",
    "\n",
    "```\n",
    "\n",
    "- *¿Cuáles son los cinco autores que han escrito más libros?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "0: jdbc:hive2://localhost:10000/> -- Selecciona los 5 autores con más libros\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> USE librosdb;\n",
      "INFO  : Compiling command(queryId=hive_20201229052929_b1a15240-65e2-416c-9f30-2ab3c70ef099): USE librosdb\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052929_b1a15240-65e2-416c-9f30-2ab3c70ef099); Time taken: 0.058 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052929_b1a15240-65e2-416c-9f30-2ab3c70ef099): USE librosdb\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20201229052929_b1a15240-65e2-416c-9f30-2ab3c70ef099); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.114 seconds)\n",
      "0: jdbc:hive2://localhost:10000/> \n",
      "0: jdbc:hive2://localhost:10000/> SELECT DISTINCT author_name\n",
      ". . . . . . . . . . . . . . . . > FROM authors, dataset LEFT SEMI JOIN (\n",
      "os. . . . . . . . . . . . . . . >     SELECT author_id, count(title) AS num_libr \n",
      ". . . . . . . . . . . . . . . . >     FROM dataset\n",
      ". . . . . . . . . . . . . . . . >     GROUP BY author_id\n",
      ". . . . . . . . . . . . . . . . >     ORDER BY num_libros DESC\n",
      ". . . . . . . . . . . . . . . . >     LIMIT 5\n",
      ". . . . . . . . . . . . . . . . > ) AS a\n",
      ". . . . . . . . . . . . . . . . > ON dataset.author_id = a.author_id\n",
      ". . . . . . . . . . . . . . . . > WHERE authors.author_id = dataset.author_id;\n",
      "INFO  : Compiling command(queryId=hive_20201229052929_9d2f51ab-623b-4375-8c92-881b7f530555): SELECT DISTINCT author_name\n",
      "FROM authors, dataset LEFT SEMI JOIN (\n",
      "SELECT author_id, count(title) AS num_libros\n",
      "FROM dataset\n",
      "GROUP BY author_id\n",
      "ORDER BY num_libros DESC\n",
      "LIMIT 5\n",
      ") AS a\n",
      "ON dataset.author_id = a.author_id\n",
      "WHERE authors.author_id = dataset.author_id\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:author_name, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20201229052929_9d2f51ab-623b-4375-8c92-881b7f530555); Time taken: 0.451 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20201229052929_9d2f51ab-623b-4375-8c92-881b7f530555): SELECT DISTINCT author_name\n",
      "FROM authors, dataset LEFT SEMI JOIN (\n",
      "SELECT author_id, count(title) AS num_libros\n",
      "FROM dataset\n",
      "GROUP BY author_id\n",
      "ORDER BY num_libros DESC\n",
      "LIMIT 5\n",
      ") AS a\n",
      "ON dataset.author_id = a.author_id\n",
      "WHERE authors.author_id = dataset.author_id\n",
      "INFO  : Query ID = hive_20201229052929_9d2f51ab-623b-4375-8c92-881b7f530555\n",
      "INFO  : Total jobs = 6\n",
      "INFO  : Launching Job 1 out of 6\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1604927967949_0005, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0005/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0005\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2020-12-29 05:29:46,001 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:29:52,742 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.44 sec\n",
      "INFO  : 2020-12-29 05:29:59,019 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 580 msec\n",
      "INFO  : Ended Job = job_1604927967949_0005\n",
      "INFO  : Launching Job 2 out of 6\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1604927967949_0006, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0006/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0006\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2020-12-29 05:30:06,255 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:30:12,522 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.65 sec\n",
      "INFO  : 2020-12-29 05:30:18,776 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.53 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 530 msec\n",
      "INFO  : Ended Job = job_1604927967949_0006\n",
      "INFO  : Starting task [Stage-9:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-10 is filtered out by condition resolver.\n",
      "INFO  : Stage-11 is selected by condition resolver.\n",
      "INFO  : Stage-3 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-11:MAPREDLOCAL] in serial mode\n",
      "Execution log at: /var/log/hive/hive-server2.log\n",
      "2020-12-29 05:30:22\tStarting to launch local task to process map join;\tmaximum memory = 932184064\n",
      "2020-12-29 05:30:23\tDump the side-table for tag: 0 with group count: 20450 into file: file:/tmp/hive/6132de0c-bca4-490a-8ed9-0a19a16a6731/hive_2020-12-29_05-29-40_842_4130706512536511328-2/-local-10009/HashTable-Stage-8/MapJoin-mapfile40--.hashtable\n",
      "2020-12-29 05:30:23\tUploaded 1 File to: file:/tmp/hive/6132de0c-bca4-490a-8ed9-0a19a16a6731/hive_2020-12-29_05-29-40_842_4130706512536511328-2/-local-10009/HashTable-Stage-8/MapJoin-mapfile40--.hashtable (759301 bytes)\n",
      "2020-12-29 05:30:23\tDump the side-table for tag: 2 with group count: 5 into file: file:/tmp/hive/6132de0c-bca4-490a-8ed9-0a19a16a6731/hive_2020-12-29_05-29-40_842_4130706512536511328-2/-local-10009/HashTable-Stage-8/MapJoin-mapfile42--.hashtable\n",
      "2020-12-29 05:30:23\tUploaded 1 File to: file:/tmp/hive/6132de0c-bca4-490a-8ed9-0a19a16a6731/hive_2020-12-29_05-29-40_842_4130706512536511328-2/-local-10009/HashTable-Stage-8/MapJoin-mapfile42--.hashtable (360 bytes)\n",
      "2020-12-29 05:30:23\tEnd of local task; Time Taken: 1.525 sec.\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 4 out of 6\n",
      "INFO  : Starting task [Stage-8:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : Starting Job = job_1604927967949_0007, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0007/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0007\n",
      "INFO  : Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2020-12-29 05:30:30,433 Stage-8 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:30:35,659 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 3.05 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 50 msec\n",
      "INFO  : Ended Job = job_1604927967949_0007\n",
      "INFO  : Launching Job 5 out of 6\n",
      "INFO  : Starting task [Stage-4:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1604927967949_0008, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1604927967949_0008/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1604927967949_0008\n",
      "INFO  : Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2020-12-29 05:30:42,339 Stage-4 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-12-29 05:30:48,858 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 0.79 sec\n",
      "INFO  : 2020-12-29 05:30:55,181 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 0.79 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 160 msec\n",
      "INFO  : Ended Job = job_1604927967949_0008\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 3398021 HDFS Write: 433569 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.53 sec   HDFS Read: 438335 HDFS Write: 196 SUCCESS\n",
      "INFO  : Stage-Stage-8: Map: 1   Cumulative CPU: 3.05 sec   HDFS Read: 3398896 HDFS Write: 266 SUCCESS\n",
      "INFO  : Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 2.16 sec   HDFS Read: 4812 HDFS Write: 85 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 15 seconds 320 msec\n",
      "INFO  : Completed executing command(queryId=hive_20201229052929_9d2f51ab-623b-4375-8c92-881b7f530555); Time taken: 76.05 seconds\n",
      "INFO  : OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--+\r\n",
      "|      author_name      |\r\n",
      "+-----------------------+--+\r\n",
      "| AA Publishing         |\r\n",
      "| Distinctive Journals  |\r\n",
      "| Gregory a Boyd J D    |\r\n",
      "| Molly Elodie Rose     |\r\n",
      "| Rand McNally          |\r\n",
      "+-----------------------+--+\r\n",
      "5 rows selected (76.573 seconds)\r\n",
      "0: jdbc:hive2://localhost:10000/> \r\n",
      "0: jdbc:hive2://localhost:10000/> \r\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\r\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -f db/ej4_c.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los contenidos de ej4_c.hql son los siguientes:\n",
    "```HiveQL\n",
    "-- Selecciona los 5 autores con más libros\n",
    "\n",
    "USE librosdb;\n",
    "\n",
    "SELECT DISTINCT author_name\n",
    "FROM authors, dataset LEFT SEMI JOIN (\n",
    "    SELECT author_id, count(title) AS num_libros\n",
    "    FROM dataset\n",
    "    GROUP BY author_id\n",
    "    ORDER BY num_libros DESC\n",
    "    LIMIT 5\n",
    ") AS a\n",
    "ON dataset.author_id = a.author_id\n",
    "WHERE authors.author_id = dataset.author_id;\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Ej. 5. *Desarrolla el código MapReduce en Python que implemente la oprimera consulta del apartado anterior.*\n",
    "\n",
    "La función map definida en *mapper.py*:\n",
    "```python\n",
    "#!/usr/bin/python\n",
    "#\n",
    "# Autor: Martin Romera Sobrado\n",
    "# Contacto: mromera95@alumno.uned.es\n",
    "# \n",
    "# Sintaxis: Python 2\n",
    "#\n",
    "# Funcion map para obtener el bestseller entre los libros\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "first_line = True\n",
    "title = 0\n",
    "rank = 2\n",
    "bestrank = -1\n",
    "bestranktitle = \"\"\n",
    "\n",
    "data = sys.stdin.readlines()\n",
    "\n",
    "for line in csv.reader(data, delimiter=';'):\n",
    "    if line[rank] != \"\" and line[title] != \"title\" and line[rank] != \"bestsellers-rank\":\n",
    "        # El libro tiene ranking\n",
    "        thisrank = int(line[rank].replace('.','').replace(',',''))\n",
    "        if thisrank < bestrank or bestrank == -1 :\n",
    "            # Ha encontrado un libro con mejor ranking, o todavia no tenia un libro con mejor ranking\n",
    "            bestrank = thisrank\n",
    "            bestranktitle = line[title]\n",
    "\n",
    "print(\"%s\\t%s\" % (str(bestrank), bestranktitle))\n",
    "```\n",
    "\n",
    "Y la función reduce definida en *reducer.py*:\n",
    "```python\n",
    "#!/usr/bin/python\n",
    "#\n",
    "# Autor: Martin Romera Sobrado\n",
    "# Contacto: mromera95@alumno.uned.es\n",
    "# \n",
    "# Sintaxis: Python 2\n",
    "#\n",
    "# Funcion reduce para obtener el bestseller entre los libros\n",
    "\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "\n",
    "bestrank = -1\n",
    "besttitle = \"\"\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line.strip()\n",
    "    rank, title = line.split('\\t',1)\n",
    "\n",
    "    if bestrank == -1 or rank < bestrank:\n",
    "        # Encuentra un libro con mejor ranking, o no tenia todavia un libro con mejor ranking\n",
    "        bestrank = rank\n",
    "        besttitle = title\n",
    "\n",
    "    print(\"%s\" % (besttitle))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! chmod +x mapreduce/bestseller/mapper.py mapreduce/bestseller/reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put db/csv/authors.csv librosdb/authors # Al llegar a este paso los archivos desaparecen del HDFS por algun motivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put db/csv/dataset.csv librosdb/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/12/29 05:31:03 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [mapreduce/bestseller/mapper.py, mapreduce/bestseller/reducer.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.12.0.jar] /tmp/streamjob4329337999696246688.jar tmpDir=null\n",
      "20/12/29 05:31:05 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "20/12/29 05:31:05 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "20/12/29 05:31:05 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "20/12/29 05:31:05 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "20/12/29 05:31:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1604927967949_0009\n",
      "20/12/29 05:31:06 INFO impl.YarnClientImpl: Submitted application application_1604927967949_0009\n",
      "20/12/29 05:31:06 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1604927967949_0009/\n",
      "20/12/29 05:31:06 INFO mapreduce.Job: Running job: job_1604927967949_0009\n",
      "20/12/29 05:31:12 INFO mapreduce.Job: Job job_1604927967949_0009 running in uber mode : false\n",
      "20/12/29 05:31:12 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/12/29 05:31:17 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "20/12/29 05:31:18 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/12/29 05:31:23 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/12/29 05:31:23 INFO mapreduce.Job: Job job_1604927967949_0009 completed successfully\n",
      "20/12/29 05:31:24 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=140\n",
      "\t\tFILE: Number of bytes written=386061\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3395402\n",
      "\t\tHDFS: Number of bytes written=164\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6147\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3365\n",
      "\t\tTotal time spent by all map tasks (ms)=6147\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3365\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6147\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3365\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=6294528\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=3445760\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=36081\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=130\n",
      "\t\tMap output materialized bytes=146\n",
      "\t\tInput split bytes=252\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=146\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=4\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=61\n",
      "\t\tCPU time spent (ms)=2450\n",
      "\t\tPhysical memory (bytes) snapshot=798461952\n",
      "\t\tVirtual memory (bytes) snapshot=4714835968\n",
      "\t\tTotal committed heap usage (bytes)=874512384\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3395150\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=164\n",
      "20/12/29 05:31:24 INFO streaming.StreamJob: Output directory: /user/cloudera/librosdb/ej5-mapreduce-output\n"
     ]
    }
   ],
   "source": [
    "! hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\\\n",
    "-file mapreduce/bestseller/mapper.py \\\\\n",
    "-mapper ./mapreduce/bestseller/mapper.py \\\\\n",
    "-file mapreduce/bestseller/reducer.py \\\\\n",
    "-reducer ./mapreduce/bestseller/reducer.py \\\\\n",
    "-input /user/cloudera/librosdb/dataset/* \\\\\n",
    "-output /user/cloudera/librosdb/ej5-mapreduce-output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlas Obscura, 2nd Edition : An Explorer's Guide to the World's Hidden Wonders\t\r\n",
      "\t\r\n",
      "Atlas Obscura, 2nd Edition : An Explorer's Guide to the World's Hidden Wonders\t\r\n",
      "\t\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -text /user/cloudera/librosdb/ej5-mapreduce-output/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
